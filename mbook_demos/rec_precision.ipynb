{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Precision and Recall",
   "id": "e85f99028541fc1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Understanding Precision and Recall\n",
    "Precision and Recall are two fundamental metrics used to evaluate the performance of a recommendation system. Here's what they mean in the context of your recommendation system:\n",
    "\n",
    "Precision:\n",
    "\n",
    "Definition: Precision is the ratio of relevant items (true positives) to the total number of recommended items.\n",
    "Interpretation: Precision measures the accuracy of the recommendations, i.e., how many of the recommended items are actually relevant to the user.\n",
    "Formula: \n",
    "Precision\n",
    "=\n",
    "Number of relevant recommended items\n",
    "Total number of recommended items\n",
    "Precision= \n",
    "Total number of recommended items\n",
    "Number of relevant recommended items\n",
    "​\n",
    " \n",
    "Example: If you recommend 5 books to a user and 2 of them are relevant, the precision is \n",
    "2\n",
    "5\n",
    "=\n",
    "0.4\n",
    "5\n",
    "2\n",
    "​\n",
    " =0.4.\n",
    "Recall:\n",
    "\n",
    "Definition: Recall is the ratio of relevant items (true positives) to the total number of relevant items that should have been recommended.\n",
    "Interpretation: Recall measures the completeness of the recommendations, i.e., how many of the relevant items were actually recommended to the user.\n",
    "Formula: \n",
    "Recall\n",
    "=\n",
    "Number of relevant recommended items\n",
    "Total number of relevant items\n",
    "Recall= \n",
    "Total number of relevant items\n",
    "Number of relevant recommended items\n",
    "​\n",
    " \n",
    "Example: If there are 10 relevant books for a user and you recommend 5 books, out of which 2 are relevant, the recall is \n",
    "2\n",
    "10\n",
    "=\n",
    "0.2\n",
    "10\n",
    "2\n",
    "​\n",
    " =0.2.\n",
    "Results Interpretation\n",
    "Your current results:\n",
    "\n",
    "Books >= 2: Mean Precision@5: 0.13, Mean Recall@5: 0.32\n",
    "Books >= 5: Mean Precision@5: 0.18, Mean Recall@5: 0.33\n",
    "Books >= 10: Mean Precision@5: 0.23, Mean Recall@5: 0.32\n",
    "Analysis:\n",
    "Precision increases as the minimum number of books per user increases. This suggests that filtering out users with fewer interactions helps improve the accuracy of the recommendations.\n",
    "Recall remains relatively stable. This indicates that the system's ability to find all relevant items does not significantly change with different thresholds.\n",
    "Improving the Model\n",
    "Since you're using a sparse matrix and cosine similarity approach, here are a few additional suggestions to improve your model:\n",
    "\n",
    "Content-Based Filtering:\n",
    "\n",
    "Use additional features (e.g., genres, authors) to enrich the similarity computation.\n",
    "Hybrid Models:\n",
    "\n",
    "Combine collaborative filtering (your current approach) with content-based filtering to leverage the strengths of both methods.\n",
    "Parameter Tuning:\n",
    "\n",
    "Experiment with different values for the number of recommendations (top_n).\n",
    "Normalization:\n",
    "\n",
    "Normalize the interaction values before computing similarities to account for different user behaviors.\n"
   ],
   "id": "789fbc66fa3b13c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Improving Your Recommendation Model\n",
    "Given your current results and the goal to improve your model, here are several strategies:\n",
    "\n",
    "Data Enrichment:\n",
    "\n",
    "User and Item Metadata: Incorporate additional features such as user demographics, item metadata (genre, author, etc.) to provide more context for recommendations.\n",
    "Interaction Types: Differentiate between types of user interactions (e.g., clicks, purchases, ratings).\n",
    "Advanced Algorithms:\n",
    "\n",
    "Matrix Factorization: Use techniques like Singular Value Decomposition (SVD) or Alternating Least Squares (ALS) for collaborative filtering.\n",
    "Content-Based Filtering: Combine collaborative filtering with content-based filtering.\n",
    "Hybrid Models: Integrate multiple recommendation techniques to leverage their strengths.\n",
    "Parameter Tuning:\n",
    "\n",
    "Experiment with different values of k for recommendations.\n",
    "Use cross-validation to find optimal parameters for your model.\n",
    "Evaluation Metrics:\n",
    "\n",
    "Besides precision and recall, consider using metrics like Mean Average Precision (MAP) and Normalized Discounted Cumulative Gain (NDCG).\n",
    "Implementing Matrix Factorization using SVD\n",
    "Here’s how you can implement a basic SVD-based recommendation system\n"
   ],
   "id": "394d4752f6d8275c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import svds\n",
    "import time\n",
    "\n",
    "top_n = 5\n",
    "prec_k = 5\n",
    "filePath = 'data/purchase_history_10.csv'\n",
    "\n",
    "def run_rec_precision():\n",
    "    total_start_time = time.time()\n",
    "    print(f\"Total recommendation process started at: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(total_start_time))}\")\n",
    "    print(\"Running recommendation script...\")\n",
    "\n",
    "    # Fetch purchase history as DataFrame from file\n",
    "    purchase_history = fetch_purchase_history_from_file(filePath)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_data, test_data = train_test_split(purchase_history, test_size=0.2, random_state=42)\n",
    "    print(f\"Training data size: {len(train_data)}, Testing data size: {len(test_data)}\")\n",
    "\n",
    "    # Create the user-item matrix for the training set\n",
    "    purchase_counts = train_data.groupby(['user_id', 'book_id']).size().unstack(fill_value=0)\n",
    "    sparse_purchase_counts = sparse.csr_matrix(purchase_counts)\n",
    "    \n",
    "    # Perform SVD\n",
    "    U, sigma, Vt = svds(sparse_purchase_counts, k=50)\n",
    "    sigma = np.diag(sigma)\n",
    "\n",
    "    # Reconstruct the user-item matrix\n",
    "    reconstructed_matrix = np.dot(np.dot(U, sigma), Vt)\n",
    "    reconstructed_df = pd.DataFrame(reconstructed_matrix, columns=purchase_counts.columns, index=purchase_counts.index)\n",
    "\n",
    "    def recommend_items(user_id, n=top_n):\n",
    "        if user_id not in reconstructed_df.index:\n",
    "            return []\n",
    "\n",
    "        user_predictions = reconstructed_df.loc[user_id].sort_values(ascending=False)\n",
    "        user_history = purchase_counts.loc[user_id].to_numpy().nonzero()[0]\n",
    "        recommendations = [book_id for book_id in user_predictions.index if book_id not in user_history][:n]\n",
    "        return recommendations\n",
    "\n",
    "    # Fetch book details from file\n",
    "    book_details = fetch_books_from_file('data/books.csv')\n",
    "\n",
    "    # Evaluate the model on the testing set\n",
    "    test_user_ids = test_data['user_id'].unique()\n",
    "    all_recommendations = []\n",
    "\n",
    "    for user_id in test_user_ids:\n",
    "        recommendations = recommend_items(user_id)\n",
    "        all_recommendations.extend([(user_id, book_id) for book_id in recommendations])\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision, recall = calculate_precision_recall(test_data, all_recommendations, k=prec_k)\n",
    "    print(f\"Mean Precision@5: {precision:.2f}\")\n",
    "    print(f\"Mean Recall@5: {recall:.2f}\")\n",
    "\n",
    "def calculate_precision_recall(test_data, recommendations, k=prec_k):\n",
    "    test_set = set((row['user_id'], row['book_id']) for _, row in test_data.iterrows())\n",
    "    user_recommendations = {}\n",
    "\n",
    "    for user_id, book_id in recommendations:\n",
    "        if user_id not in user_recommendations:\n",
    "            user_recommendations[user_id] = []\n",
    "        user_recommendations[user_id].append(book_id)\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for user_id in test_data['user_id'].unique():\n",
    "        true_positives = 0\n",
    "        recommended_books = user_recommendations.get(user_id, [])\n",
    "        relevant_books = test_data[test_data['user_id'] == user_id]['book_id'].tolist()\n",
    "\n",
    "        for book_id in recommended_books[:k]:\n",
    "            if book_id in relevant_books:\n",
    "                true_positives += 1\n",
    "\n",
    "        precision = true_positives / k\n",
    "        recall = true_positives / len(relevant_books) if len(relevant_books) > 0 else 0\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "\n",
    "    return mean_precision, mean_recall\n",
    "\n",
    "# Fetch purchase history from file\n",
    "def fetch_purchase_history_from_file(file_path):\n",
    "    print(\"Fetching purchase history from file\")\n",
    "    start_time = time.time()\n",
    "    df = pd.read_csv(file_path)\n",
    "    end_time = time.time()\n",
    "    fetch_time = end_time - start_time\n",
    "    print(f\"Fetch time: {fetch_time:.2f} seconds\")\n",
    "    print(f\"Size: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# Fetch book details from file\n",
    "def fetch_books_from_file(file_path):\n",
    "    print(\"Fetching books from file...\")\n",
    "    start_time = time.time()\n",
    "    df = pd.read_csv(file_path)\n",
    "    end_time = time.time()\n",
    "    fetch_time = end_time - start_time\n",
    "    print(f\"Fetch time: {fetch_time:.2f} seconds\")\n",
    "    print(f\"Size: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "run_rec_precision()\n"
   ],
   "id": "7ea52c5c85bee71d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2ee6d08cadc56b30"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
